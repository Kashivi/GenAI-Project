{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":128431,"databundleVersionId":15477148,"sourceType":"competition"}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!ls /kaggle/input/jan-2026-dl-gen-ai-project\n!ls /kaggle/input/jan-2026-dl-gen-ai-project/messy_mashup\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T19:36:21.553771Z","iopub.execute_input":"2026-02-18T19:36:21.554183Z","iopub.status.idle":"2026-02-18T19:36:22.013781Z","shell.execute_reply.started":"2026-02-18T19:36:21.554154Z","shell.execute_reply":"2026-02-18T19:36:22.012298Z"}},"outputs":[{"name":"stdout","text":"messy_mashup\nESC-50-master  genres_stems  mashups  sample_submission.csv  test.csv\n","output_type":"stream"}],"execution_count":311},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport librosa\nimport librosa.display\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom typing import Dict\nimport os\nimport glob\nimport random\nimport torch\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T19:36:22.016720Z","iopub.execute_input":"2026-02-18T19:36:22.017135Z","iopub.status.idle":"2026-02-18T19:36:22.026621Z","shell.execute_reply.started":"2026-02-18T19:36:22.017098Z","shell.execute_reply":"2026-02-18T19:36:22.025152Z"}},"outputs":[],"execution_count":312},{"cell_type":"code","source":"BASE_PATH = \"/kaggle/input/jan-2026-dl-gen-ai-project/messy_mashup\"\n\nGENRES_PATH = os.path.join(BASE_PATH, \"genres_stems\")\nMASHUPS_PATH = os.path.join(BASE_PATH, \"mashups\")\nESC_PATH = os.path.join(BASE_PATH, \"ESC-50-master\")\nTEST_CSV = os.path.join(BASE_PATH, \"test.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T19:36:22.028124Z","iopub.execute_input":"2026-02-18T19:36:22.028548Z","iopub.status.idle":"2026-02-18T19:36:22.050740Z","shell.execute_reply.started":"2026-02-18T19:36:22.028515Z","shell.execute_reply":"2026-02-18T19:36:22.049355Z"}},"outputs":[],"execution_count":313},{"cell_type":"code","source":"#----------------------------- DON'T CHANGE THIS --------------------------\nDATA_SEED = 67\nTRAINING_SEED = 1234\nSR = 22050\nDURATION = 5.0\nN_FFT = 2048\nHOP_LENGTH = 512\nN_MELS = 128\nTOP_DB=20\nTARGET_SNR_DB = 10\n\nrandom.seed(DATA_SEED)\nnp.random.seed(DATA_SEED)\ntorch.manual_seed(DATA_SEED)\ntorch.cuda.manual_seed(DATA_SEED)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T19:36:22.054076Z","iopub.execute_input":"2026-02-18T19:36:22.054411Z","iopub.status.idle":"2026-02-18T19:36:22.089149Z","shell.execute_reply.started":"2026-02-18T19:36:22.054382Z","shell.execute_reply":"2026-02-18T19:36:22.084414Z"}},"outputs":[],"execution_count":314},{"cell_type":"code","source":"DATA_ROOT = \"/kaggle/input/jan-2026-dl-gen-ai-project/messy_mashup/genres_stems\"\n\nGENRES = sorted(os.listdir(DATA_ROOT))\n\nSTEMS = [\"drums.wav\", \"vocals.wav\", \"bass.wav\", \"other.wav\"]\n\nSTEM_KEYS = ['drums', 'vocals', 'bass', 'other']\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T19:36:22.092141Z","iopub.execute_input":"2026-02-18T19:36:22.092928Z","iopub.status.idle":"2026-02-18T19:36:22.109524Z","shell.execute_reply.started":"2026-02-18T19:36:22.092772Z","shell.execute_reply":"2026-02-18T19:36:22.108094Z"}},"outputs":[],"execution_count":315},{"cell_type":"code","source":"# Question - 1\n\n# Constants\nKB = 1024\nMB = 1024 * 1024\n\nCORRUPTED_THRESHOLD = 4 * KB\nSMALL_FILE_THRESHOLD = 5.0491 * MB\n\n\ndef build_dataset(root_dir, val_split=0.17, seed=42):\n    # Initialize empty dictionaries\n    train_dataset = {g: {s.replace('.wav', ''): [] for s in STEMS} for g in GENRES}\n    val_dataset   = {g: {s.replace('.wav', ''): [] for s in STEMS} for g in GENRES}\n\n    rng = random.Random(seed)\n\n    corrupted_count = 0\n    small_file_count = 0\n\n    for genre in GENRES:\n        genre_path = os.path.join(root_dir, genre)\n\n        # Check if genre folder exists\n        if not os.path.exists(genre_path):\n            continue\n\n        valid_songs = []\n\n        for song in os.listdir(genre_path):\n            song_path = os.path.join(genre_path, song)\n\n            if not os.path.isdir(song_path):\n                continue\n\n            stems_present = True\n            stem_paths = []\n\n            # Check completeness\n            for stem in STEMS:\n                stem_path = os.path.join(song_path, stem)\n\n                if not os.path.exists(stem_path):\n                    stems_present = False\n                    break\n\n                stem_paths.append(stem_path)\n\n            if not stems_present:\n                continue\n\n            # Check corruption + size conditions\n            for stem_path in stem_paths:\n                size = os.path.getsize(stem_path)\n\n                if size < CORRUPTED_THRESHOLD:\n                    corrupted_count += 1\n\n                if size < SMALL_FILE_THRESHOLD:\n                    small_file_count += 1\n\n            valid_songs.append(song)\n\n        # Stratified shuffle split\n        rng.shuffle(valid_songs)\n        split_idx = int(len(valid_songs) * (1 - val_split))\n\n        train_songs = valid_songs[:split_idx]\n        val_songs   = valid_songs[split_idx:]\n\n        # Helper function to populate dictionary\n        def add_to_dict(target_dict, song_list):\n            for song in song_list:\n                song_path = os.path.join(genre_path, song)\n                for stem in STEMS:\n                    stem_key = stem.replace('.wav', '')\n                    stem_path = os.path.join(song_path, stem)\n                    target_dict[genre][stem_key].append(stem_path)\n\n        add_to_dict(train_dataset, train_songs)\n        add_to_dict(val_dataset, val_songs)\n\n    total_required_answer = corrupted_count + small_file_count\n\n    print(\"Corrupted (<4KB):\", corrupted_count)\n    print(\"Files < 5.0491MB:\", small_file_count)\n    print(\"Final Answer (Q1):\", total_required_answer)\n\n    return train_dataset, val_dataset\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T19:36:22.111582Z","iopub.execute_input":"2026-02-18T19:36:22.111899Z","iopub.status.idle":"2026-02-18T19:36:22.130256Z","shell.execute_reply.started":"2026-02-18T19:36:22.111873Z","shell.execute_reply":"2026-02-18T19:36:22.128805Z"}},"outputs":[],"execution_count":316},{"cell_type":"code","source":"tr, val = build_dataset(DATA_ROOT)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T19:36:22.132251Z","iopub.execute_input":"2026-02-18T19:36:22.132718Z","iopub.status.idle":"2026-02-18T19:36:25.151104Z","shell.execute_reply.started":"2026-02-18T19:36:22.132684Z","shell.execute_reply":"2026-02-18T19:36:25.150160Z"}},"outputs":[{"name":"stdout","text":"Corrupted (<4KB): 0\nFiles < 5.0491MB: 1256\nFinal Answer (Q1): 1256\n","output_type":"stream"}],"execution_count":317},{"cell_type":"code","source":"# Question 2\n\nLOWER_THRESHOLD = 5.0491 * MB\nUPPER_THRESHOLD = 5.0493 * MB\n\ngreater_than_upper = 0\nless_than_lower = 0\n\nfor genre in GENRES:\n    genre_path = os.path.join(DATA_ROOT, genre)\n\n    if not os.path.exists(genre_path):\n        continue\n\n    for song in os.listdir(genre_path):\n        song_path = os.path.join(genre_path, song)\n\n        if not os.path.isdir(song_path):\n            continue\n\n        for stem in STEMS:\n            stem_path = os.path.join(song_path, stem)\n\n            if not os.path.exists(stem_path):\n                continue\n\n            size = os.path.getsize(stem_path)\n\n            if size > UPPER_THRESHOLD:\n                greater_than_upper += 1\n\n            if size < LOWER_THRESHOLD:\n                less_than_lower += 1\n\n\nabsolute_difference = abs(greater_than_upper - less_than_lower)\n\nprint(\"Sounds > 5.0493MB:\", greater_than_upper)\nprint(\"Sounds < 5.0491MB:\", less_than_lower)\nprint(\"Absolute Difference (Q2):\", absolute_difference)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T19:36:25.152368Z","iopub.execute_input":"2026-02-18T19:36:25.152745Z","iopub.status.idle":"2026-02-18T19:36:25.225878Z","shell.execute_reply.started":"2026-02-18T19:36:25.152719Z","shell.execute_reply":"2026-02-18T19:36:25.224861Z"}},"outputs":[{"name":"stdout","text":"Sounds > 5.0493MB: 184\nSounds < 5.0491MB: 1256\nAbsolute Difference (Q2): 1072\n","output_type":"stream"}],"execution_count":318},{"cell_type":"code","source":"# Question 3\n\ntrain_reggae_drums = len(tr[\"reggae\"][\"drums\"])\nval_country_vocals = len(val[\"country\"][\"vocals\"])\n\nabsolute_difference_q3 = abs(train_reggae_drums - val_country_vocals)\n\nprint(\"Training Reggae Drum Samples:\", train_reggae_drums)\nprint(\"Validation Country Vocal Samples:\", val_country_vocals)\nprint(\"Absolute Difference (Q3):\", absolute_difference_q3)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T19:36:25.227443Z","iopub.execute_input":"2026-02-18T19:36:25.227776Z","iopub.status.idle":"2026-02-18T19:36:25.233998Z","shell.execute_reply.started":"2026-02-18T19:36:25.227749Z","shell.execute_reply":"2026-02-18T19:36:25.233026Z"}},"outputs":[{"name":"stdout","text":"Training Reggae Drum Samples: 83\nValidation Country Vocal Samples: 17\nAbsolute Difference (Q3): 66\n","output_type":"stream"}],"execution_count":319},{"cell_type":"code","source":"# Question 4\ndef find_long_silences(dataset_dict, sr=SR, threshold_sec=DURATION, top_db=TOP_DB):\n    \"\"\"\n    Input:\n        dataset_dict: {genre: {stem: [paths...]}}\n    Output:\n        df: DataFrame of files with silence >= threshold_sec\n    \"\"\"\n    records = []\n    total_files = 0\n\n    for genre in dataset_dict:\n        for stem_name in dataset_dict[genre]:\n            for file_path in dataset_dict[genre][stem_name]:\n\n                total_files += 1\n\n                # ---- Load Audio ----\n                y, sr = librosa.load(file_path, sr=sr)\n                total_duration = librosa.get_duration(y=y, sr=sr)\n\n                # ---- Find Non-Silent Intervals ----\n                intervals = librosa.effects.split(y, top_db=top_db)\n\n                silence_durations = []\n                silence_type = []\n\n                # ---- CASE A: Fully Silent ----\n                if len(intervals) == 0:\n                    max_silence = total_duration\n                    silence_type.append(\"Full\")\n                else:\n                    max_silence = 0\n\n                    # ---- CASE B: Start Silence ----\n                    if intervals[0][0] > 0:\n                        start_silence = intervals[0][0] / sr\n                        silence_durations.append(start_silence)\n                        silence_type.append(\"Start\")\n\n                    # ---- CASE D: Middle Silence ----\n                    for i in range(len(intervals) - 1):\n                        end_current = intervals[i][1]\n                        start_next = intervals[i+1][0]\n                        gap = (start_next - end_current) / sr\n                        silence_durations.append(gap)\n                        silence_type.append(\"Middle\")\n\n                    # ---- CASE C: End Silence ----\n                    if intervals[-1][1] < len(y):\n                        end_silence = (len(y) - intervals[-1][1]) / sr\n                        silence_durations.append(end_silence)\n                        silence_type.append(\"End\")\n\n                    if silence_durations:\n                        max_silence = max(silence_durations)\n                    else:\n                        max_silence = 0\n\n                # ---- Store result ----\n                if max_silence >= threshold_sec:\n                    records.append({\n                        \"Genre\": genre,\n                        \"Stem\": stem_name,\n                        \"Duration\": round(total_duration, 2),\n                        \"Max_Silence_Sec\": round(max_silence, 2),\n                        \"Silence_Location\": \", \".join(set(silence_type)),\n                        \"File_Path\": file_path\n                    })\n\n    df = pd.DataFrame(records)\n\n    print(\"Total Files Checked:\", total_files)\n    print(\"Files with Silence >= {} sec:\".format(threshold_sec), len(df))\n\n    return df\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T19:36:25.237438Z","iopub.execute_input":"2026-02-18T19:36:25.237880Z","iopub.status.idle":"2026-02-18T19:36:25.261114Z","shell.execute_reply.started":"2026-02-18T19:36:25.237842Z","shell.execute_reply":"2026-02-18T19:36:25.259807Z"}},"outputs":[],"execution_count":320},{"cell_type":"code","source":"df_silence = find_long_silences(tr, threshold_sec=DURATION, top_db=TOP_DB)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T19:36:25.262676Z","iopub.execute_input":"2026-02-18T19:36:25.263141Z","iopub.status.idle":"2026-02-18T19:41:53.073305Z","shell.execute_reply.started":"2026-02-18T19:36:25.263106Z","shell.execute_reply":"2026-02-18T19:41:53.072114Z"}},"outputs":[{"name":"stdout","text":"Total Files Checked: 3320\nFiles with Silence >= 5.0 sec: 678\n","output_type":"stream"}],"execution_count":321},{"cell_type":"code","source":"# Question 5\n# Count only vocals from silence dataframe\ntotal_vocal_long_silence = len(df_silence[df_silence[\"Stem\"] == \"vocals\"])\n\nprint(\"Total number of vocal tracks with silence >= 5 seconds:\",\n      total_vocal_long_silence)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T19:41:53.082281Z","iopub.execute_input":"2026-02-18T19:41:53.082673Z","iopub.status.idle":"2026-02-18T19:41:53.113246Z","shell.execute_reply.started":"2026-02-18T19:41:53.082639Z","shell.execute_reply":"2026-02-18T19:41:53.112206Z"}},"outputs":[{"name":"stdout","text":"Total number of vocal tracks with silence >= 5 seconds: 315\n","output_type":"stream"}],"execution_count":323},{"cell_type":"code","source":"# Question 6\n# Filter only vocals\nvocal_silence_df = df_silence[df_silence[\"Stem\"] == \"vocals\"]\n\n# Compute average silence length\naverage_silence_vocals = vocal_silence_df[\"Max_Silence_Sec\"].mean()\n\nprint(\"Average Silence Length in Vocals (secs):\",\n      round(average_silence_vocals, 2))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T19:41:53.114485Z","iopub.execute_input":"2026-02-18T19:41:53.114822Z","iopub.status.idle":"2026-02-18T19:41:53.138841Z","shell.execute_reply.started":"2026-02-18T19:41:53.114784Z","shell.execute_reply":"2026-02-18T19:41:53.137765Z"}},"outputs":[{"name":"stdout","text":"Average Silence Length in Vocals (secs): 12.78\n","output_type":"stream"}],"execution_count":324},{"cell_type":"code","source":"print(\"Total vocal files considered:\", len(vocal_silence_df))\nprint(\"Min silence:\", vocal_silence_df[\"Max_Silence_Sec\"].min())\nprint(\"Max silence:\", vocal_silence_df[\"Max_Silence_Sec\"].max())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T19:41:53.140254Z","iopub.execute_input":"2026-02-18T19:41:53.140693Z","iopub.status.idle":"2026-02-18T19:41:53.166547Z","shell.execute_reply.started":"2026-02-18T19:41:53.140653Z","shell.execute_reply":"2026-02-18T19:41:53.165454Z"}},"outputs":[{"name":"stdout","text":"Total vocal files considered: 315\nMin silence: 5.02\nMax silence: 29.73\n","output_type":"stream"}],"execution_count":325},{"cell_type":"code","source":"# Question 7\njazz_drum_silence_count = len(\n    df_silence[\n        (df_silence[\"Genre\"] == \"jazz\") &\n        (df_silence[\"Stem\"] == \"drums\")\n    ]\n)\n\nprint(\"Total number of jazz drum tracks with silence >= 5 seconds:\",\n      jazz_drum_silence_count)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T19:41:53.167793Z","iopub.execute_input":"2026-02-18T19:41:53.168171Z","iopub.status.idle":"2026-02-18T19:41:53.191272Z","shell.execute_reply.started":"2026-02-18T19:41:53.168138Z","shell.execute_reply":"2026-02-18T19:41:53.190148Z"}},"outputs":[{"name":"stdout","text":"Total number of jazz drum tracks with silence >= 5 seconds: 20\n","output_type":"stream"}],"execution_count":326},{"cell_type":"code","source":"# Question 8\njazz_drum_middle_only = len(\n    df_silence[\n        (df_silence[\"Genre\"] == \"jazz\") &\n        (df_silence[\"Stem\"] == \"drums\") &\n        (df_silence[\"Silence_Location\"] == \"Middle\")\n    ]\n)\n\nprint(\"Jazz drum tracks with silence >=5s and only middle silence:\",\n      jazz_drum_middle_only)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T19:41:53.192451Z","iopub.execute_input":"2026-02-18T19:41:53.192920Z","iopub.status.idle":"2026-02-18T19:41:53.214750Z","shell.execute_reply.started":"2026-02-18T19:41:53.192887Z","shell.execute_reply":"2026-02-18T19:41:53.213847Z"}},"outputs":[{"name":"stdout","text":"Jazz drum tracks with silence >=5s and only middle silence: 0\n","output_type":"stream"}],"execution_count":327},{"cell_type":"code","source":"# Question 9\njazz_drum_long_silence = len(\n    df_silence[\n        (df_silence[\"Genre\"] == \"jazz\") &\n        (df_silence[\"Stem\"] == \"drums\") &\n        (df_silence[\"Max_Silence_Sec\"] >= 10)\n    ]\n)\n\nprint(\"Jazz drum tracks with silence >=5s and Max_Silence_Sec >= 10:\",\n      jazz_drum_long_silence)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T19:41:53.216167Z","iopub.execute_input":"2026-02-18T19:41:53.216560Z","iopub.status.idle":"2026-02-18T19:41:53.244073Z","shell.execute_reply.started":"2026-02-18T19:41:53.216533Z","shell.execute_reply":"2026-02-18T19:41:53.242959Z"}},"outputs":[{"name":"stdout","text":"Jazz drum tracks with silence >=5s and Max_Silence_Sec >= 10: 7\n","output_type":"stream"}],"execution_count":328},{"cell_type":"code","source":"# Question 10\nstems_audio = []\n\nGENRE_TO_TEST = \"rock\"\nSONG_INDEX = 0  # first song\n\ntry:\n    for key in STEM_KEYS:\n        # Get file path\n        file_path = tr[GENRE_TO_TEST][key][SONG_INDEX]\n\n        # Load exactly 5 seconds\n        y, sr = librosa.load(file_path, sr=SR, duration=5.0)\n\n        stems_audio.append(y)\n\n    # Ensure equal length (important!)\n    min_length = min(len(stem) for stem in stems_audio)\n    stems_audio = [stem[:min_length] for stem in stems_audio]\n\n    # Combine stems\n    mix = np.sum(stems_audio, axis=0)\n\n    print(\"Audio loaded successfully.\")\n    print(\"Length of mix sample:\", len(mix))\n\nexcept NameError:\n    print(\"ERROR: 'tr' dictionary not found. Please run build_dataset() first.\")\nexcept IndexError:\n    print(f\"ERROR: Song index {SONG_INDEX} out of range.\")\nexcept Exception as e:\n    print(f\"ERROR: {e}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T19:41:53.245479Z","iopub.execute_input":"2026-02-18T19:41:53.245858Z","iopub.status.idle":"2026-02-18T19:41:53.311249Z","shell.execute_reply.started":"2026-02-18T19:41:53.245823Z","shell.execute_reply":"2026-02-18T19:41:53.310285Z"}},"outputs":[{"name":"stdout","text":"Audio loaded successfully.\nLength of mix sample: 110250\n","output_type":"stream"}],"execution_count":329},{"cell_type":"code","source":"# Question 11 and 12\n\n# Stack stems into numpy array (4 x Samples)\nstems_stack = np.vstack(stems_audio)\n\n# Mix stems by summing element-wise\nmix_raw = np.sum(stems_stack, axis=0)\n\n# ----- RMS Amplitude (MANUAL) -----\nrms_val = np.sqrt(np.mean(mix_raw ** 2))\n\n# ----- Peak Normalization -----\nmax_val = np.max(np.abs(mix_raw))\n\nif max_val > 0:\n    mix_norm = mix_raw / max_val\nelse:\n    mix_norm = mix_raw\n\n# VALIDATION\nassert np.isclose(np.max(np.abs(mix_norm)), 1.0), \"Normalization failed.\"\n\nprint(\"RMS Amplitude of mix sample:\", rms_val)\nprint(\"Max value of peak normalized sample:\", np.max(np.abs(mix_norm)))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T19:41:53.312328Z","iopub.execute_input":"2026-02-18T19:41:53.312666Z","iopub.status.idle":"2026-02-18T19:41:53.323089Z","shell.execute_reply.started":"2026-02-18T19:41:53.312641Z","shell.execute_reply":"2026-02-18T19:41:53.321862Z"}},"outputs":[{"name":"stdout","text":"RMS Amplitude of mix sample: 0.16697016\nMax value of peak normalized sample: 1.0\n","output_type":"stream"}],"execution_count":330}]}